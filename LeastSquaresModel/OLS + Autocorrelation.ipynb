{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wicked-jesus",
   "metadata": {},
   "source": [
    "# Least Squares Methodologies with Python\n",
    "\n",
    "In this notebook we will go over an example of how to perform Ordinary Least Squares regression (single x + y) as well as Multiple Linear Regression using python. We will also look at generating autocorrelation plots.\n",
    "\n",
    "As usual we start by importing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "increasing-health",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       x    y          z\n",
      "0   -5.0 -5.0 -15.126964\n",
      "1   -4.5 -5.0 -19.835269\n",
      "2   -4.0 -5.0 -17.584515\n",
      "3   -3.5 -5.0 -17.218906\n",
      "4   -3.0 -5.0  -9.403777\n",
      "..   ...  ...        ...\n",
      "436  3.0  5.0   3.399930\n",
      "437  3.5  5.0   7.101061\n",
      "438  4.0  5.0   8.426533\n",
      "439  4.5  5.0  13.369264\n",
      "440  5.0  5.0  11.353852\n",
      "\n",
      "[441 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = pd.read_csv(os.getcwd() + os.sep + \"regressiondata.csv\", index_col = \"Unnamed: 0\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-health",
   "metadata": {},
   "source": [
    "## Least Squares Regression with a Single Variable\n",
    "\n",
    "In our data set we have z as the dependent variable, and x and y as the independent variables. We will first analyze how our model performs using just the x variable to predict z.\n",
    "\n",
    "Regression models can be built in python using the `from statsmodels.formula.api` library, which contains an `ols` class. The ols class takes as input a DataFrame as well as a string expression indicating which form the regression model should take based on the column names of the dataframe. The general format is \"dependent_var_col_name ~ independent_var1_col_name + independent_var2_col_name + ...\". This is easier shown with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "characteristic-migration",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "model = ols(\"z ~ x\", data)\n",
    "results = model.fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-victoria",
   "metadata": {},
   "source": [
    "In the above example we are building a model to predict z (the dependent variable) based on the values of x (the independent variable). The `ols` command create the ols model object while the `.fit()` command computes the regression model and returns the model results. Let's see what's contained in the results of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mighty-variety",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.893\n",
      "Model:                            OLS   Adj. R-squared:                  0.892\n",
      "Method:                 Least Squares   F-statistic:                     3649.\n",
      "Date:                Tue, 02 Nov 2021   Prob (F-statistic):          7.92e-215\n",
      "Time:                        17:45:26   Log-Likelihood:                -1263.5\n",
      "No. Observations:                 441   AIC:                             2531.\n",
      "Df Residuals:                     439   BIC:                             2539.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -4.8145      0.203    -23.753      0.000      -5.213      -4.416\n",
      "x              4.0440      0.067     60.407      0.000       3.912       4.176\n",
      "==============================================================================\n",
      "Omnibus:                        2.929   Durbin-Watson:                   1.002\n",
      "Prob(Omnibus):                  0.231   Jarque-Bera (JB):                2.879\n",
      "Skew:                          -0.154   Prob(JB):                        0.237\n",
      "Kurtosis:                       2.750   Cond. No.                         3.03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-malta",
   "metadata": {},
   "source": [
    "In this example:\n",
    "* The intercept term (b0) = -4.8145\n",
    "* The slope term (b1) = 4.0440 - this implies that on average a unit increase in x results in an increase of z of 4.0440 units\n",
    "* The z-value for the intercept term is -23.753 - Python calls this the t-value because it comes from the t-distribution but in our notes we called it the z-value\n",
    "* The 95% confidence interval bounds for the intercept are \\[-5.213, -4.416\\]. \n",
    "* The 95% confidence intervals for the slope term are \\[3.912, 4.176\\].\n",
    "* The confidence intervals do not cross zero meaning that zero is not a plausible value for the coefficients. x therefore significantly impacts the value of z.\n",
    "* The $R^2$ value is 0.893\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-tiffany",
   "metadata": {},
   "source": [
    "Let's investigate the results in more detail by checking the ANOVA table. ANOVA related methods canm be found in the `statsmodels.stats.anova` library in the `anova_lm` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dressed-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df        sum_sq       mean_sq            F         PR(>F)\n",
      "x           1.0  66110.897036  66110.897036  3649.019713  7.922701e-215\n",
      "Residual  439.0   7953.556321     18.117440          NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.anova import anova_lm\n",
    "anova_results = anova_lm(results)\n",
    "print(anova_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-student",
   "metadata": {},
   "source": [
    "A key additional piece of information we haven't got yet is the standard error of the model. The `scale` parameter of the model results provides the residual sum of squares. The square root of this value is the standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constitutional-subscription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model standard error is: 4.256458664901206\n"
     ]
    }
   ],
   "source": [
    "RSS = results.scale\n",
    "print(\"The model standard error is: \" + str(np.sqrt(RSS)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-prague",
   "metadata": {},
   "source": [
    "Lastly, in order to use the model, we want to get the model coefficients without having to hard code the values. They are contained inside the model results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "nervous-emperor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.81446239  4.04400339]\n"
     ]
    }
   ],
   "source": [
    "coefficients = results._results.params\n",
    "print(coefficients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conceptual-orange",
   "metadata": {},
   "source": [
    "There is an alternate way to build linear regression models that are syntactically cleaner. They can be found in the `OLS` class in the `statsmodels.api` library. The drawback to this 'cleaner' method is that it doesn't provide convenient access to the model's ANOVA table. In cases where the ANOVA results aren't needed it may provide a cleaner solution.\n",
    "\n",
    "By default this version DOES NOT include an intercept term. The intercept term needs to be added manually via the `add_constant` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "operating-underground",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.893\n",
      "Model:                            OLS   Adj. R-squared:                  0.892\n",
      "Method:                 Least Squares   F-statistic:                     3649.\n",
      "Date:                Tue, 02 Nov 2021   Prob (F-statistic):          7.92e-215\n",
      "Time:                        17:45:26   Log-Likelihood:                -1263.5\n",
      "No. Observations:                 441   AIC:                             2531.\n",
      "Df Residuals:                     439   BIC:                             2539.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.8145      0.203    -23.753      0.000      -5.213      -4.416\n",
      "x              4.0440      0.067     60.407      0.000       3.912       4.176\n",
      "==============================================================================\n",
      "Omnibus:                        2.929   Durbin-Watson:                   1.002\n",
      "Prob(Omnibus):                  0.231   Jarque-Bera (JB):                2.879\n",
      "Skew:                          -0.154   Prob(JB):                        0.237\n",
      "Kurtosis:                       2.750   Cond. No.                         3.03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "x = sm.add_constant(data['x'])\n",
    "model = sm.OLS(data['z'], x)\n",
    "results_other_method = model.fit()\n",
    "print(results_other_method.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-johns",
   "metadata": {},
   "source": [
    "Comparing the results from the second method with the results from the first confirms they are the same. The standard error and the coefficients can be accessed in the same way as the previous method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-tyler",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Thus far we have built our model for z based solely on x. However, z is actually dependent on both x and y. Let's see how we can build a model using both variables. We talked about the syntax before but it's better shown with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handy-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLR_model = ols(\"z ~ x + y\", data)\n",
    "MLR_results = MLR_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-casino",
   "metadata": {},
   "source": [
    "In this case we build a model for z based on both x and y. Arbitrarily many terms can be added to the model in this manner. Let's take a look at the results for this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "handy-thomas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      z   R-squared:                       0.948\n",
      "Model:                            OLS   Adj. R-squared:                  0.947\n",
      "Method:                 Least Squares   F-statistic:                     3964.\n",
      "Date:                Tue, 02 Nov 2021   Prob (F-statistic):          2.87e-281\n",
      "Time:                        17:45:26   Log-Likelihood:                -1105.1\n",
      "No. Observations:                 441   AIC:                             2216.\n",
      "Df Residuals:                     438   BIC:                             2229.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -4.8145      0.142    -33.979      0.000      -5.093      -4.536\n",
      "x              4.0440      0.047     86.412      0.000       3.952       4.136\n",
      "y             -1.0041      0.047    -21.455      0.000      -1.096      -0.912\n",
      "==============================================================================\n",
      "Omnibus:                        0.260   Durbin-Watson:                   2.057\n",
      "Prob(Omnibus):                  0.878   Jarque-Bera (JB):                0.204\n",
      "Skew:                          -0.052   Prob(JB):                        0.903\n",
      "Kurtosis:                       3.015   Cond. No.                         3.03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "print(MLR_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-proposal",
   "metadata": {},
   "source": [
    "The results here look similar to the results above but we have an additional y term. The y term gives the slope coefficient for the y variable as well as the confidence intervals for it. The same commands for the single variable model can also be used on the multiple variable model so I won't repeat examples for them here. \n",
    "\n",
    "Some notes on the interpretation of the results:\n",
    "* The $R^2$ value increased from 0.89 to 0.95 which seems to inficate that y impacts z, but we need to confirm with the CIs\n",
    "* Looking at the CIs - both x and y are significant factors to predict z as the 95% CIs for both parameters DO NOT cross 0\n",
    "* Holding y fixed a unit increase in x increases z by on average 4.044 units\n",
    "* Holding x fixed a unit increase in y DECREASES z by on average -1.0041 units\n",
    "\n",
    "For reference the function for z in this case is: $z = 4*x -1*y - 5$ plus the addition of some random noise. We can see from the results summary that the true values for all of our parameters fall in the 95% confidence intervals!\n",
    "\n",
    "The ANOVA table can also be calcualted for the MLR model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "auburn-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             df        sum_sq       mean_sq            F         PR(>F)\n",
      "x           1.0  66110.897036  66110.897036  7467.069259  2.721206e-277\n",
      "y           1.0   4075.652970   4075.652970   460.335351   2.540995e-70\n",
      "Residual  438.0   3877.903351      8.853661          NaN            NaN\n"
     ]
    }
   ],
   "source": [
    "print(anova_lm(MLR_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-gravity",
   "metadata": {},
   "source": [
    "In this case we have two regression sum of square values, one for the x and one for the y. The total $R^2$ value can be calculated by summing up the x and y sum_sq value and dividing by the total sum squared values.\n",
    "\n",
    "## Autocorrelation\n",
    "\n",
    "One thing we talked about during the lectures is the concept of autocorrelation. We said that one of the assumptions for our calculation of the model parameter's confidence intervals is that the data should be independent. Often engineering is NOT independent as it is gathered in time. One data point is then likely to be correlated with the value before it. We discussed how autocorrelation can be checked using an autocorrelation plot. `Matplotlib` offers a convenient way to plot the autocorrelation function using the `acorr` method. Let's see an example below to test if our z value is autocorrelated. The number of lags to show on the plot can be specified with the `maxlags` argument. Let's show 6 lag values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "resistant-honey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.acorr(data['z'], maxlags=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "celtic-official",
   "metadata": {},
   "source": [
    "By default `matplotlib` shows two sided autocorrelation plot. We're only interested in the right side so let's change our x-limits on the plot to only show the right side. The x limits of the plot can be specified using the `xlim` option. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "auburn-argentina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.acorr(data['z'], maxlags=5)\n",
    "plt.xlim([0,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-metropolitan",
   "metadata": {},
   "source": [
    "In this example the data seems to be mildly autocorrelated. But the results we presented were still good! The CIs we calcualted for our model parameters contained the true values of our parameters. As we discussed in the video lectures, Least Squares regression models are pretty robust to violations of our assumptions. That being said, we should always validate our assumptions and understand \"how much\" we are violating them by!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-survivor",
   "metadata": {},
   "source": [
    "## MLR with categorical variables\n",
    "\n",
    "Let's now look at MLR including categorical variables. In this case we will look at the BirthWeight data set. The outcome of interest is the weight at birth of 32 randomly selected babies. For each birth, along with the weight of the baby, the baby’s gestational age at birth (how many weeks in the mother’s womb prior to birth) and whether the mother smoked tobacco products was also recorded. \n",
    "\n",
    "Since the process of fitting the model is the same we'll go through this quickly and simply focus on the interpretation of the Python output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accredited-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Birthweight_g  Gestational_age_weeks Mother_Smokes\n",
      "0           2940                     38           yes\n",
      "1           3130                     38            no\n",
      "2           2420                     36           yes\n",
      "3           2450                     34            no\n",
      "4           2760                     39           yes\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Birthweight_g   R-squared:                       0.896\n",
      "Model:                            OLS   Adj. R-squared:                  0.889\n",
      "Method:                 Least Squares   F-statistic:                     125.4\n",
      "Date:                Tue, 02 Nov 2021   Prob (F-statistic):           5.29e-15\n",
      "Time:                        17:45:27   Log-Likelihood:                -195.82\n",
      "No. Observations:                  32   AIC:                             397.6\n",
      "Df Residuals:                      29   BIC:                             402.0\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=========================================================================================\n",
      "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------\n",
      "Intercept             -2389.5729    349.206     -6.843      0.000   -3103.779   -1675.366\n",
      "Mother_Smokes[T.yes]   -244.5440     41.982     -5.825      0.000    -330.406    -158.682\n",
      "Gestational_age_weeks   143.1003      9.128     15.677      0.000     124.431     161.769\n",
      "==============================================================================\n",
      "Omnibus:                        1.946   Durbin-Watson:                   2.016\n",
      "Prob(Omnibus):                  0.378   Jarque-Bera (JB):                1.162\n",
      "Skew:                          -0.090   Prob(JB):                        0.559\n",
      "Kurtosis:                       2.084   Cond. No.                         663.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.getcwd() + os.sep + \"BirthWeight.csv\", delimiter=';')\n",
    "print(data.head())\n",
    "model_results = ols(\"Birthweight_g ~ Gestational_age_weeks + Mother_Smokes\", data).fit()\n",
    "print(model_results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "upper-corrections",
   "metadata": {},
   "source": [
    "The only difference to what we've discussed so far is how Python reports the results for the categorical variable. The table reports the coefficient values for \"Mother_Smokes\" along with \\[T.Yes\\]. This implies that mother smokes is given a value of $d=1$ and non-smokers is given a value of $d=0$ (our equation is of the form $Birthweight = b_0 + b_1*Gestational\\_age\\_weeks + gd_i$).\n",
    "\n",
    "Our interpretation of the model is as follows:\n",
    "* Both gestational age and mother smokes significantly impact birthweight because the 95% CI for those coefficients do NOT contain zero\n",
    "* The coefficient for gestational age is 143.1/week meaning that for each week the baby gestates the average weight at birth increases by 143.1g (holding smoking status fixed)\n",
    "* The coefficient for mother smokes is -244.5 meaning that mothers who smoke gave birth to babies that are on average 244.5g less than mothers who do not smoke, holding gestational age fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
