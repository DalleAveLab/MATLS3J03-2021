{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "emerging-ballot",
   "metadata": {},
   "source": [
    "# Factorial Experiments\n",
    "\n",
    "While at its core, the multiple linear regression that goes along with the Design of Experiments section is the same as we saw earlier, there are some nuances related to building the models and interpreting the output. \n",
    "\n",
    "Let's take a look at the example from slide 45 of the Design of Experiments lectures (week 8). In this case, we had a 2 factor factorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "level-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "A = np.array([-1, 1, -1, 1])\n",
    "B = np.array([-1, -1, 1, 1])\n",
    "y = [69, 60, 64, 53]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-knock",
   "metadata": {},
   "source": [
    "In the least squares GutHub tutorial we built this model by manually typing out the $X$ matrix and then fitting the model. There is an easier way to do this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cubic-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ols(\"y~A*B\", {'y': y, 'A': A, 'B': B})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-classification",
   "metadata": {},
   "source": [
    "Creating the model in the above manner automatically generates the 2 factor interaction. Let's see what the results of the model are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "regional-comedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Sun, 07 Nov 2021   Prob (F-statistic):                nan\n",
      "Time:                        10:30:50   Log-Likelihood:                 126.02\n",
      "No. Observations:                   4   AIC:                            -244.0\n",
      "Df Residuals:                       0   BIC:                            -246.5\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     61.5000        inf          0        nan         nan         nan\n",
      "A             -5.0000        inf         -0        nan         nan         nan\n",
      "B             -3.0000        inf         -0        nan         nan         nan\n",
      "A:B           -0.5000        inf         -0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.500\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.167\n",
      "Skew:                           0.000   Prob(JB):                        0.920\n",
      "Kurtosis:                       2.000   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\base\\model.py:1452: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n"
     ]
    }
   ],
   "source": [
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-facing",
   "metadata": {},
   "source": [
    "The A:B interaction is automatically included and we get the same coefficients as we calculated in the lectures! \n",
    "\n",
    "Note that the Python output includes several warnings reminding us that we don't have the necessary degrees of freedom to calculate the standard error and therefore the confidence intervals of the model coefficients (among other values). The corresponding values in the table are some variation of undefined (either inf or nan)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-jacksonville",
   "metadata": {},
   "source": [
    "## Fractional Factorials\n",
    "\n",
    "One issue that complicates things in Python is when we do fractional experiments. Let's look at an example where we have three factors but we're running a half factorial. To generate the half factorial we define C = AB. A and B are the same in this case as defined above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "commercial-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1  1]\n"
     ]
    }
   ],
   "source": [
    "C = A*B\n",
    "y = [30, 6, 4, 4]\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vulnerable-homework",
   "metadata": {},
   "source": [
    "Now let's build the model and see our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-acquisition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Sun, 07 Nov 2021   Prob (F-statistic):                nan\n",
      "Time:                        10:30:50   Log-Likelihood:                 127.29\n",
      "No. Observations:                   4   AIC:                            -246.6\n",
      "Df Residuals:                       0   BIC:                            -249.0\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.5000        inf          0        nan         nan         nan\n",
      "A             -3.0000        inf         -0        nan         nan         nan\n",
      "B             -3.5000        inf         -0        nan         nan         nan\n",
      "A:B            3.0000        inf          0        nan         nan         nan\n",
      "C              3.0000        inf          0        nan         nan         nan\n",
      "A:C           -3.5000        inf         -0        nan         nan         nan\n",
      "B:C           -3.0000        inf         -0        nan         nan         nan\n",
      "A:B:C          5.5000        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.529\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.755\n",
      "Skew:                           0.993   Prob(JB):                        0.686\n",
      "Kurtosis:                       2.235   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The input rank is higher than the number of observations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    }
   ],
   "source": [
    "model=ols(\"y~A*B*C\", {'y': y, 'A': A, 'B': B, 'C':C})\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "computational-reading",
   "metadata": {},
   "source": [
    "The results look somewhat strange. How are we estimating 8 coefficients (3 main effects + 3 two factor interactions + 1 three factor interaction + intercept) if we only have 4 data points? The reason for this is that several of the effects are confounded! Python reports the total coefficient values, split among all the different terms that are confounded!\n",
    "\n",
    "We defined in the lectures that the defining relationship in this case is $I=ABC$. Based on this defining relationship we determined that A is alisased with BC, B is aliased with AC, C is aliased with AB (by design), and that the intercept is aliased with ABC. The coefficients are therefore represented as follows: \n",
    "\n",
    "$b_0 + b_{ABC} = \\hat{\\beta_0}$ \n",
    "\n",
    "$b_A + b_{BC} = \\hat{\\beta_A}$\n",
    "\n",
    "$b_B + b_{AC} = \\hat{\\beta_B}$\n",
    "\n",
    "$b_C + b_{AB} = \\hat{\\beta_C}$\n",
    "\n",
    "The linear model can therefore be written as follows: $y_i = \\hat{\\beta_0} + \\hat{\\beta_A}x_a + \\hat{\\beta_B}x_b + \\hat{\\beta_C}x_c = (5.5 + 5.5) + (-3 -3)x_a + (-3.5 -3.5)x_b + (3 +3)x_c = 11 -6x_a -7x_b + 6x_c$\n",
    "\n",
    "Note that in this case each coefficient was created by two aliased terms. If more terms are aliased, Python will split the coefficient value between all those terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-passion",
   "metadata": {},
   "source": [
    "Another way to do this is to simply include the terms that you want in the model definition. In the above example we know that for a half $2^3$ factorial we can only estimate the three main effects (confounded with the two factor interactions) and the intercept (confounded with the three factor interaction) for a total of 4 coefficients. If we want the value of the coefficients directly, instead of using the `*` notation to generate the interaction effects automatically we can just include the three terms in the model that we want. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "charged-ferry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                    nan\n",
      "Method:                 Least Squares   F-statistic:                       nan\n",
      "Date:                Sun, 07 Nov 2021   Prob (F-statistic):                nan\n",
      "Time:                        10:30:50   Log-Likelihood:                 125.65\n",
      "No. Observations:                   4   AIC:                            -243.3\n",
      "Df Residuals:                       0   BIC:                            -245.8\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     11.0000        inf          0        nan         nan         nan\n",
      "A             -6.0000        inf         -0        nan         nan         nan\n",
      "B             -7.0000        inf         -0        nan         nan         nan\n",
      "C              6.0000        inf          0        nan         nan         nan\n",
      "==============================================================================\n",
      "Omnibus:                          nan   Durbin-Watson:                   1.942\n",
      "Prob(Omnibus):                    nan   Jarque-Bera (JB):                0.394\n",
      "Skew:                           0.359   Prob(JB):                        0.821\n",
      "Kurtosis:                       1.642   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\stats\\stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 4 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1728: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1650: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "c:\\users\\degidal\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\statsmodels\\base\\model.py:1452: RuntimeWarning: invalid value encountered in multiply\n",
      "  cov_p = self.normalized_cov_params * scale\n"
     ]
    }
   ],
   "source": [
    "model=ols(\"y~A+B+C\", {'y': y, 'A': A, 'B': B, 'C':C})\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-connection",
   "metadata": {},
   "source": [
    "The coefficients we get above are the same as when we included the interaction terms and combine the confounded ones manually. \n",
    "\n",
    "To summarize, in the OLS function the `*` operator can be used to automatically generate the interaction terms between the different variables. That being said, care needs to be taken when interpreting the output. If variables are confounded, Python will split the actual coefficient value evenly between all the confounded terms. The coefficient can  then be recovered by summing up the coefficient for the confounded term. Altenately this can be accounted for manually during the model definition, by only including the desired columns. The reported coefficient value in this case is still confounded, but only a single value is reported based on how we defined the model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
